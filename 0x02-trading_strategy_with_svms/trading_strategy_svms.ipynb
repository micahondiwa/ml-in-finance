{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long/short Trading Strategy with Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The aim is to implement SVM on a trading strategy for the Luxembourg index (LUXXX) based on other indices as well as technical indicators. \n",
    "- The strategy is to take a long/short position when 0.25% change in LUXXX return is predicted. \n",
    "- The long/short position will be based on an upward or downward trending market.\n",
    "- This strategy does not take into account  trading costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the data: The data contains weekly closing prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>LUXXX</th>\n",
       "      <th>MSCI ARGENTINA</th>\n",
       "      <th>BLP ORIENTE MEDIO</th>\n",
       "      <th>MSCI AUSTRALIA</th>\n",
       "      <th>MSCI AUSTRIA</th>\n",
       "      <th>MSCI BELGIUM</th>\n",
       "      <th>MSCI BRAZIL</th>\n",
       "      <th>MSCI CANADA</th>\n",
       "      <th>MSCI CHINA</th>\n",
       "      <th>...</th>\n",
       "      <th>MSCI NORWAY</th>\n",
       "      <th>MSCI PERU</th>\n",
       "      <th>MSCI RUSSIA</th>\n",
       "      <th>MSCI SINGAPORE</th>\n",
       "      <th>MSCI SOUTH AFRICA</th>\n",
       "      <th>MSCI SPAIN</th>\n",
       "      <th>MSCI SWEDEN</th>\n",
       "      <th>MSCI SWITZERLAND</th>\n",
       "      <th>MSCI UK</th>\n",
       "      <th>MSCI USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-Jan-16</td>\n",
       "      <td>1390.716</td>\n",
       "      <td>2376.29</td>\n",
       "      <td>3525.9150</td>\n",
       "      <td>1068.79</td>\n",
       "      <td>106.70</td>\n",
       "      <td>105.38</td>\n",
       "      <td>1036.23</td>\n",
       "      <td>1663.27</td>\n",
       "      <td>59.47</td>\n",
       "      <td>...</td>\n",
       "      <td>2373.17</td>\n",
       "      <td>811.96</td>\n",
       "      <td>404.73</td>\n",
       "      <td>1507.8101</td>\n",
       "      <td>1255.75</td>\n",
       "      <td>108.40</td>\n",
       "      <td>11136.65</td>\n",
       "      <td>1148.37</td>\n",
       "      <td>1818.40</td>\n",
       "      <td>1949.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08-Jan-16</td>\n",
       "      <td>1291.267</td>\n",
       "      <td>2260.85</td>\n",
       "      <td>3280.6683</td>\n",
       "      <td>1005.56</td>\n",
       "      <td>97.66</td>\n",
       "      <td>99.35</td>\n",
       "      <td>952.01</td>\n",
       "      <td>1586.18</td>\n",
       "      <td>54.63</td>\n",
       "      <td>...</td>\n",
       "      <td>2209.38</td>\n",
       "      <td>751.09</td>\n",
       "      <td>388.05</td>\n",
       "      <td>1437.6600</td>\n",
       "      <td>1177.76</td>\n",
       "      <td>101.00</td>\n",
       "      <td>10389.93</td>\n",
       "      <td>1075.30</td>\n",
       "      <td>1722.00</td>\n",
       "      <td>1831.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15-Jan-16</td>\n",
       "      <td>1257.086</td>\n",
       "      <td>2217.50</td>\n",
       "      <td>3118.2981</td>\n",
       "      <td>985.38</td>\n",
       "      <td>93.54</td>\n",
       "      <td>97.32</td>\n",
       "      <td>904.64</td>\n",
       "      <td>1541.08</td>\n",
       "      <td>51.54</td>\n",
       "      <td>...</td>\n",
       "      <td>2095.60</td>\n",
       "      <td>720.23</td>\n",
       "      <td>344.45</td>\n",
       "      <td>1372.9800</td>\n",
       "      <td>1133.72</td>\n",
       "      <td>97.34</td>\n",
       "      <td>10042.32</td>\n",
       "      <td>1056.01</td>\n",
       "      <td>1692.43</td>\n",
       "      <td>1789.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     LUXXX  MSCI ARGENTINA  BLP ORIENTE MEDIO  MSCI AUSTRALIA  \\\n",
       "0  01-Jan-16  1390.716         2376.29          3525.9150         1068.79   \n",
       "1  08-Jan-16  1291.267         2260.85          3280.6683         1005.56   \n",
       "2  15-Jan-16  1257.086         2217.50          3118.2981          985.38   \n",
       "\n",
       "   MSCI AUSTRIA  MSCI BELGIUM  MSCI BRAZIL  MSCI CANADA  MSCI CHINA  ...  \\\n",
       "0        106.70        105.38      1036.23      1663.27       59.47  ...   \n",
       "1         97.66         99.35       952.01      1586.18       54.63  ...   \n",
       "2         93.54         97.32       904.64      1541.08       51.54  ...   \n",
       "\n",
       "   MSCI NORWAY  MSCI PERU  MSCI RUSSIA  MSCI SINGAPORE  MSCI SOUTH AFRICA  \\\n",
       "0      2373.17     811.96       404.73       1507.8101            1255.75   \n",
       "1      2209.38     751.09       388.05       1437.6600            1177.76   \n",
       "2      2095.60     720.23       344.45       1372.9800            1133.72   \n",
       "\n",
       "   MSCI SPAIN  MSCI SWEDEN  MSCI SWITZERLAND  MSCI UK  MSCI USA  \n",
       "0      108.40     11136.65           1148.37  1818.40   1949.70  \n",
       "1      101.00     10389.93           1075.30  1722.00   1831.88  \n",
       "2       97.34     10042.32           1056.01  1692.43   1789.56  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/luxxx.csv\")\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'Date' column is in a string format; therefore, convert it to a datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_6944\\939905822.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data_df[\"Date\"] = pd.to_datetime(data_df[\"Date\"])\n"
     ]
    }
   ],
   "source": [
    "data_df[\"Date\"] = pd.to_datetime(data_df[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specifying the target column - the LUXXX index. The returns of LUXXX needs to be calculated since our strategy is based on the returns over the weeks. \n",
    "- The remaining indices are converted to returns instead of their prices; to scale the features into a common unit as well as to capture movements in the prices instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ETF = \"LUXXX\"\n",
    "\n",
    "ETF_features = data_df.loc[:, ~data_df.columns.isin([\"Date\", target_ETF])].columns\n",
    "data_df[ETF_features] = data_df[ETF_features].pct_change()\n",
    "\n",
    "data_df[target_ETF + \"_returns\"] = data_df[target_ETF].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we calculate the Target column and converts it into a categorical binary variable. \n",
    "- Denote 1 for the absolute returns of LUXXX exceeding 0.25% and 0 otherwise. In a downward or bear market, we look to short should the price decrease by more than this threshold, and we take a long position in a bear market. \n",
    "- The goal is to predict a percent change more than a threshold. \n",
    "- We shift the target column by one week to align with the predicted period available for other predictors since the ML algorithm re quires the label and feature/predictor values to be captured in the same row or observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[target_ETF + \"_returns\" + \"_shift\"] = data_df[target_ETF + \"_returns\"].shift(-1)\n",
    "\n",
    "# Strategy to take long position for anticipated returns of 0.5%\n",
    "data_df[\"Target\"] = np.where(\n",
    "(data_df[target_ETF + \"_returns_shift\"].abs() > 0.025), 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3452"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking target proportion\n",
    "round(data_df[\"Target\"].sum() / len(data_df), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The proportion of 34.5% of the target class 1 does not indicate any imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have our Target class, we can select which indices contribute to predicting the target class. We use the feature importance tool in Sklearn for a Decision Tree.\n",
    "- We look at the cumulative importance for the features that make a contribution > 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 21\u001b[0m\n\u001b[0;32m     11\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m DTree \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(\n\u001b[0;32m     14\u001b[0m     criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m \u001b[43mDTree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     24\u001b[0m     DTree\u001b[38;5;241m.\u001b[39mfeature_importances_,\n\u001b[0;32m     25\u001b[0m     index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39miloc[:, :]\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     26\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportances\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportances\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m feature_importances[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCumul_Imp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m feature_importances\u001b[38;5;241m.\u001b[39mcumsum()\u001b[38;5;241m.\u001b[39miloc[:, :]\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:257\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    251\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    253\u001b[0m     X, y, validate_separately\u001b[38;5;241m=\u001b[39m(check_X_params, check_y_params)\n\u001b[0;32m    254\u001b[0m )\n\u001b[0;32m    256\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_missing_values_in_feature_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    260\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:222\u001b[0m, in \u001b[0;36mBaseDecisionTree._compute_missing_values_in_feature_mask\u001b[1;34m(self, X, estimator_name)\u001b[0m\n\u001b[0;32m    218\u001b[0m     overall_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(X)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(overall_sum):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# Raise a ValueError in case of the presence of an infinite element.\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcommon_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# If the sum is not nan, then there are no missing values\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(overall_sum):\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m     )\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Prepare for Train/Test split\n",
    "\n",
    "NoNaN_df = data_df.dropna()\n",
    "X = NoNaN_df[ETF_features]\n",
    "\n",
    "X = X.iloc[:, :]\n",
    "y = NoNaN_df.loc[:, \"Target\"]\n",
    "\n",
    "del NoNaN_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "DTree = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    random_state=0,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=30,\n",
    "    min_samples_split=20,\n",
    ")\n",
    "\n",
    "DTree.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame(\n",
    "    DTree.feature_importances_,\n",
    "    index=X.iloc[:, :].columns,\n",
    "    columns=[\"importances\"],\n",
    ").sort_values(\"importances\", ascending=False)\n",
    "\n",
    "feature_importances[\"Cumul_Imp\"] = feature_importances.cumsum().iloc[:, :]\n",
    "\n",
    "pct_var = 1.0\n",
    "feature_importances = feature_importances[(feature_importances[\"Cumul_Imp\"] <= pct_var)]\n",
    "feature_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
